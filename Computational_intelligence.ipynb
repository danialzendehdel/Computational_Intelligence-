{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Computational_intelligence.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Exv6NK7AA1v1",
        "39WRvdpMCGXB",
        "SirkyB_NNXAn",
        "lqo_oxU-Oc00",
        "TYSS61P7OzRH",
        "s-7nQqLsPEWa",
        "q2aslKQ3PLui",
        "MbWPZOSKDgEq",
        "6vA7yb4zE98Z",
        "5XF0gJSEFZRv",
        "IVFB2ATGFn-4",
        "ucxwUHlQH17X",
        "BfcMEeLSKghX",
        "YXxPDKTFLN4b",
        "T9c0ygbDMcyy",
        "haHAVsZ8Qtzz",
        "cu8rhOvyRfQj",
        "tJvtBD-YRuau",
        "V7U9DzwbSSlm",
        "PfqA1pOsSkVM",
        "sY4SEKMsSreV",
        "z5gQmaTHS3Ed",
        "rSU7_s1HT-N0",
        "fW1Oj0kpT17B",
        "5EkNm_f8U1kM",
        "FmQcz4ndU6QW",
        "_5eOhYxSVATU",
        "WZlGk0lJVE93",
        "kTNZcLdOVdAY",
        "9iUzFETIVqlu",
        "4T08QI6NVqs7",
        "g0pjLx83Vq0B",
        "_QRi4j13VrCQ",
        "ki1D8e8IVrJu",
        "HvgYegrrWrqf"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOcBQJCtLHEFiJruFp3Rh/V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danialzendehdel/Computational_Intelligence-/blob/main/Computational_intelligence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Exv6NK7AA1v1"
      },
      "source": [
        "# Libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOBcIzidBYt9"
      },
      "source": [
        "import os\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "import gc\n",
        "import tensorflow as tf \n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
        "from tensorflow.keras.models import Sequential , Model \n",
        "\n",
        "from keras.preprocessing import image\n",
        "from PIL import Image, ImageDraw\n",
        "import cv2\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping , ModelCheckpoint , ReduceLROnPlateau\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Conv2D ,MaxPool2D,Input, Dropout , MaxPooling2D,Flatten,Dense,GlobalAveragePooling2D,BatchNormalization,Activation\n",
        "from keras import regularizers, optimizers \n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "\n",
        "## tensorboard\n",
        "import shutil\n",
        "\n",
        "try:\n",
        "  shutil.rmtree('logs')\n",
        "except:\n",
        "  pass\n",
        "\n",
        "\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39WRvdpMCGXB"
      },
      "source": [
        "# Colab configurations \n",
        "This part is specifically for running the code on Colab.\n",
        "\n",
        "\n",
        "1.   Check if the google has given the premission to use GPU or not.\n",
        "2.   Mount the google drive in order to import images (caustion : if you mind to use your Google Drive do not forget to download images and put them to you Drive and write the path of directory of images in code).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxNUl-OCBal5"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQnaQA8sDQgs"
      },
      "source": [
        "## my images directory\n",
        "path = '/content/gdrive/My Drive/Kaggle'\n",
        "os.chdir(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPx-NBDKDVYq"
      },
      "source": [
        "## check the path \n",
        "pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SirkyB_NNXAn"
      },
      "source": [
        "# **FUNCTIONS** \n",
        "\n",
        "1.   `plot Bounding Box Function` : This has been only used for the output of Datagenerator for Multiple output model.\n",
        "It shows images with label and bounding box just for one image at time.\n",
        "\n",
        "2.   `result_vis` : This one plot the history of Multiple output Model\n",
        "3.    `intersection_over_union` : This one measure of how much the predicted and real BBOXes have overlap \n",
        "4.    `prediction_vis` : shows the labels and bboxes\n",
        "5.     `result_images` : compute the predictions base on given model and then use the `intersection_over_union` to compute IOU the with help of `prediction_vis` shows the predicted labels bboxes with real ones.  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqo_oxU-Oc00"
      },
      "source": [
        "##**Plot bounding box**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_6B7YCfOAgF"
      },
      "source": [
        "def plot_bounding_box(image,gt_coords,pred_coords=None,norm=False) : \n",
        "  if norm : \n",
        "    # image *=255\n",
        "    image = image.astype('uint8')\n",
        "  image = Image.fromarray(image) \n",
        "  draw = ImageDraw.Draw(image)\n",
        "\n",
        "\n",
        "  xmin , ymin , xmax , ymax = gt_coords\n",
        "  xmin *= 224\n",
        "  ymin *= 224\n",
        "  xmax *= 224\n",
        "  ymax *= 224\n",
        "\n",
        "  draw.rectangle((xmin,ymin,xmax,ymax),outline='green',width=3)\n",
        "\n",
        "  if pred_coords : \n",
        "    xminp , yminp , xmaxp , ymaxp = pred_coords\n",
        "    \n",
        "    xminp *= 224\n",
        "    yminp *= 224\n",
        "    xmaxp *= 224\n",
        "    ymaxp *= 224\n",
        "    draw.rectangle((xminp,yminp,xmaxp,ymaxp),outline='red',width=3)\n",
        "\n",
        "  return image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYSS61P7OzRH"
      },
      "source": [
        "## **result_vis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjBJK-AxORsW"
      },
      "source": [
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "def result_visual(history) : \n",
        "  \n",
        "  fig = make_subplots(rows=3, cols=1,\n",
        "                      subplot_titles=(\"Total Loss\",\"Class Loss\", \"BBOX Loss\"),\n",
        "                      vertical_spacing=0.2)\n",
        "\n",
        "  # subplot_titles=(\"Plot 1\", \"Plot 2\", \"Plot 3\", \"Plot 4\",\"Plot 4\")\n",
        "\n",
        "  fig.add_trace(go.Scattergl(\n",
        "                      y=history.history['loss'],\n",
        "                      name='Train'),row=1, col=1)\n",
        "  fig.add_trace(go.Scattergl(\n",
        "                      y=history.history['val_loss'],\n",
        "                      name='Valid'),row=1, col=1)\n",
        "\n",
        "  fig.add_trace(go.Scattergl(\n",
        "                      y=history.history['class_out_loss'],\n",
        "                      name='Train'),row=2, col=1)\n",
        "  fig.add_trace(go.Scattergl(\n",
        "                      y=history.history['val_class_out_loss'],\n",
        "                      name='Valid'),row=2, col=1)\n",
        "\n",
        "  fig.add_trace(go.Scattergl(\n",
        "                      y=history.history['box_out_loss'],\n",
        "                      name='Train'),row=3, col=1)\n",
        "  fig.add_trace(go.Scattergl(\n",
        "                      y=history.history['val_box_out_loss'],\n",
        "                      name='Valid'),row=3, col=1)\n",
        "\n",
        "\n",
        "  fig.update_layout(height=800, width=700,\n",
        "                    title_text=\"LOSS\",\n",
        "                    xaxis_title='Epoch',\n",
        "                    yaxis_title='LOSS')\n",
        "  # Update xaxis properties\n",
        "  fig.update_xaxes(title_text=\"Epoch\", row=1, col=1)\n",
        "  fig.update_xaxes(title_text=\"Epoch\", row=2, col=1)\n",
        "  fig.update_xaxes(title_text=\"Epoch\", showgrid=True, row=3, col=1)\n",
        "\n",
        "\n",
        "  # Update yaxis properties\n",
        "  fig.update_yaxes(title_text=\"LOSS\", row=1, col=1)\n",
        "  fig.update_yaxes(title_text=\"LOSS\",  row=2, col=1)\n",
        "  fig.update_yaxes(title_text=\"LOSS\", showgrid=True, row=3, col=1)\n",
        "\n",
        "\n",
        "\n",
        "  fig.show()\n",
        "\n",
        "  fig2 = go.Figure()\n",
        "  fig2.add_trace(go.Scattergl(\n",
        "                      y=history.history['box_out_mae'],\n",
        "                      name='Train'))\n",
        "  fig2.add_trace(go.Scattergl(\n",
        "                      y=history.history['val_box_out_mae'],\n",
        "                      name='Valid'))\n",
        "  fig2.update_layout(height=500, \n",
        "                    width=700,\n",
        "                    title='Mean Absolute Error for age feature',\n",
        "                    xaxis_title='Epoch',\n",
        "                    yaxis_title='Mean Absolute Error')\n",
        "  fig2.show()\n",
        "\n",
        "  fig3 = go.Figure()\n",
        "  fig3.add_trace(go.Scattergl(\n",
        "                      y=history.history['class_out_accuracy'],\n",
        "                      name='Train'))\n",
        "  fig3.add_trace(go.Scattergl(\n",
        "                      y=history.history['val_class_out_accuracy'],\n",
        "                      name='Valid')\n",
        "                      )\n",
        "  fig3.update_layout(height=500, width=700,\n",
        "                    title_text=\"ACCURACY\",\n",
        "                    xaxis_title='Epoch',\n",
        "                    yaxis_title='Accuracy')\n",
        "\n",
        "\n",
        "\n",
        "  fig3.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-7nQqLsPEWa"
      },
      "source": [
        "## **IoU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yN2HUNpPKh3"
      },
      "source": [
        "def intersection_over_union(pred_box, true_box):\n",
        "\n",
        "    xmin_pred, ymin_pred, xmax_pred, ymax_pred = np.split(pred_box,4, axis = 1)\n",
        "    xmin_true, ymin_true, xmax_true, ymax_true = np.split(true_box, 4, axis = 1)\n",
        "\n",
        "    #Calculate coordinates of overlap area between boxes\n",
        "    xmin_overlap = np.maximum(xmin_pred, xmin_true)\n",
        "    xmax_overlap = np.minimum(xmax_pred, xmax_true)\n",
        "    ymin_overlap = np.maximum(ymin_pred, ymin_true)\n",
        "    ymax_overlap = np.minimum(ymax_pred, ymax_true)\n",
        "\n",
        "    #Calculates area of true and predicted boxes\n",
        "    pred_box_area = (xmax_pred - xmin_pred) * (ymax_pred - ymin_pred)\n",
        "    true_box_area = (xmax_true - xmin_true) * (ymax_true - ymin_true)\n",
        "\n",
        "    #Calculates overlap area and union area.\n",
        "    overlap_area = np.maximum((xmax_overlap - xmin_overlap),0)  * np.maximum((ymax_overlap - ymin_overlap), 0)\n",
        "    union_area = (pred_box_area + true_box_area) - overlap_area\n",
        "\n",
        "    # Defines a smoothing factor to prevent division by 0\n",
        "    smoothing_factor = 1e-10\n",
        "\n",
        "    #Updates iou score\n",
        "    iou = (overlap_area + smoothing_factor) / (union_area + smoothing_factor)\n",
        "\n",
        "    return iou"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2aslKQ3PLui"
      },
      "source": [
        "## **prediction_vis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUsXS_AaPSXU"
      },
      "source": [
        "def prediction_vis(images,gt_bbox,predict_bbox,gt_label,predict_labels,iou=None): \n",
        "\n",
        "  # Matplotlib config\n",
        "  plt.rc('image', cmap='gray')\n",
        "  plt.rc('grid', linewidth=0)\n",
        "  plt.rc('xtick', top=False, bottom=False, labelsize='large')\n",
        "  plt.rc('ytick', left=False, right=False, labelsize='large')\n",
        "  plt.rc('axes', facecolor='F8F8F8', titlesize=\"large\", edgecolor='white')\n",
        "  plt.rc('text', color='a8151a')\n",
        "  plt.rc('figure', facecolor='F0F0F0')# Matplotlib fonts\n",
        "\n",
        "  \n",
        "  counter=0\n",
        "  plt.figure(figsize=(10, 15))\n",
        "  x = len(images)\n",
        "  \n",
        "  for i in range(9) : \n",
        "    counter += 1\n",
        "    height , width,channel = 224,224,3\n",
        "    ax = plt.subplot(3,3,i+1)\n",
        "    xmin , ymin , xmax , ymax = list(gt_bbox[i])\n",
        "    xminp, yminp, xmaxp, ymaxp = list(predict_bbox[i])\n",
        "    image = Image.fromarray((images[i]).astype(np.uint8))\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    draw.rectangle((int(xmin*width),int(ymin*height),int(xmax*width),int(ymax*height)),outline='green',width=3)\n",
        "    draw.rectangle((int(xminp*width),int(yminp*height),int(xmaxp*width),int(ymaxp*height)),outline='red',width=3)\n",
        "    plt.imshow(image)\n",
        "    # if gt_label : \n",
        "    #   plt.text(int(xmin*width),\n",
        "    #            int(ymin*height),\n",
        "    #            target_dict2[np.argmax(gt_label[i])],\n",
        "    #            backgroundcolor = 'green',\n",
        "    #            horizontalalignment='right',\n",
        "    #            c='black',\n",
        "    #            size='large')\n",
        "     \n",
        "      \n",
        "    plt.text(int(xmin*width),\n",
        "             int(ymin*height),\n",
        "             target_dict2[(gt_label[i])],\n",
        "             backgroundcolor = 'green',\n",
        "             horizontalalignment='right',\n",
        "             c='black',\n",
        "             size='large')\n",
        "    plt.title('IOU : ' + str(format((iou[i][0]*100),'.2f')),size='x-large')\n",
        "   \n",
        "    # if predict_labels : \n",
        "    plt.text(int(xminp*width),int(yminp*height),\n",
        "              target_dict2[np.argmax(predict_labels[i])],\n",
        "              backgroundcolor = 'red',\n",
        "              horizontalalignment='left',\n",
        "              c='black',\n",
        "              size='x-large')\n",
        "    plt.axis(\"off\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvUPDzQhP8W2"
      },
      "source": [
        "##**result_images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg9vIBNZP8og"
      },
      "source": [
        "def result_images(images,gt_bbox,gt_label,model_test=None ,model_classification = None,model_reg= None) : \n",
        "  #Makes predictions\n",
        "  if model_test : \n",
        "    predicted_labels,predicted_bboxes = model_test.predict(images, batch_size=16)\n",
        "  else : \n",
        "    predicted_labels = model_classification.predict(images)\n",
        "    predicted_bboxes = model_reg.predict(images)\n",
        "\n",
        "    # print(predicted_labels)\n",
        "    # predicted_labels = np.argmax(predicted_labels)\n",
        "  #Calculates IOU and reports true positives and false positives based on IOU threshold\n",
        "  iou = intersection_over_union(predicted_bboxes, gt_bbox)\n",
        "  iou_threshold = 0.5\n",
        "  # print(iou)\n",
        "\n",
        "  # print(\"Number of predictions where iou > threshold(%s): %s\" % (iou_threshold, (iou >= iou_threshold).sum()))\n",
        "  # print(\"Number of predictions where iou < threshold(%s): %s\" % (iou_threshold, (iou < iou_threshold).sum()))\n",
        "\n",
        "  prediction_vis(images=images,\n",
        "               gt_bbox=(gt_bbox),\n",
        "               predict_bbox=(predicted_bboxes),\n",
        "               gt_label=gt_label,\n",
        "               predict_labels=predicted_labels,\n",
        "               iou=iou)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbWPZOSKDgEq"
      },
      "source": [
        "# **Dataset preparation** \n",
        "#**Caution: THERE IS NO NEED TO RUN THIS PART AT ALL AS THE RESULT OF THESE PART HAS SAVED**\n",
        "The originality of this Dataset is published by **Game of Deep Learning** competition [Ship Images Dataset](https://www.kaggle.com/arpitjain007/game-of-deep-learning-ship-datasets)  , because of this images in this dataset have not specific size and the sizes are different image by image and also there are some images with lack of 3 channels we used the equal dataset which has images with 128 size with 3 channels . "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydEqysziECRD"
      },
      "source": [
        "The images are imported in addition there is **.CSV** file which contains the images **filename** and **labels** which be useful just in terms of classification although in case of `Object Detection` **annotations** are needed as well so by using the benefits of `Labelimg` a new **CSV** file is created by ourself which contains _annotations_ and _Width_ and _Height_ of images in addition to previous one .The tutorial of installing and using the application is here [Labelimg](https://medium.com/deepquestai/object-detection-training-preparing-your-custom-dataset-6248679f0d1d)\n",
        "Finally the format saved data is **Pascal VOC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SMQ2tCwD-XR"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\"\n",
        "# /content/gdrive/My Drive/Kaggle is the path where kaggle.json is present in the Google Drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icMxh97cEvEh"
      },
      "source": [
        "cwd = os.getcwd()\n",
        "\n",
        "# Print the current working directory\n",
        "print(\"Current working directory: {0}\".format(cwd))\n",
        "\n",
        "# Print the type of the returned object\n",
        "print(\"os.getcwd() returns an object of type: {0}\".format(type(cwd)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7JnU3QRExVd"
      },
      "source": [
        " pip install kaggle --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWgD0TljE1yh"
      },
      "source": [
        "!kaggle datasets download -d canerbaloglu/ship-images-dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEa_HI6nE3wV"
      },
      "source": [
        "# #unzipping the zip files and deleting the zip files\n",
        "!unzip \\*.zip  && rm *.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vA7yb4zE98Z"
      },
      "source": [
        "## Parse annotations \n",
        "As the annotations has been save as `.xml` format in order to make CSV file the code below has runned then the Dataset is saved .This code is taken from `Tesnorflow Object Detection TFRecord function `,you are able to see the whole in here [TFRecord](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#convert-xml-to-record)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMyN69hJE3zQ"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "\n",
        "\n",
        "def xml_to_csv(path):\n",
        "    xml_list = []\n",
        "    # for xml_file in glob.glob(path + '/*.xml'):\n",
        "    for dir in os.listdir(path) :\n",
        "      path_temp = (os.path.join(path,dir))\n",
        "      print(path_temp)\n",
        "      # for xml_file in os.listdir(path_temp) :\n",
        "      for xml_file in glob.glob(path_temp + '/*.xml'):\n",
        "        \n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        for member in root.findall('object'):\n",
        "            value = (root.find('filename').text,\n",
        "                     int(root.find('size')[0].text),\n",
        "                     int(root.find('size')[1].text),\n",
        "                     member[0].text,\n",
        "                     int(member[4][0].text),\n",
        "                     int(member[4][1].text),\n",
        "                     int(member[4][2].text),\n",
        "                     int(member[4][3].text)\n",
        "                     )\n",
        "            xml_list.append(value)\n",
        "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "    return xml_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dT3j3ZUDFStb"
      },
      "source": [
        "**Save dataframe as .CSV file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpnUo3UYFLtJ"
      },
      "source": [
        "path_annotation = '/content/gdrive/My Drive/Kaggle/resized_images/annotation2'\n",
        "\n",
        "## Saved file as Dataframe\n",
        "xml_df = xml_to_csv(path_annotation)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XF0gJSEFZRv"
      },
      "source": [
        "# **Data Preprocessing** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVFB2ATGFn-4"
      },
      "source": [
        "\n",
        "## **Dataframe Preprocessing** \n",
        "Now as the Dataframes for both `training` and `testing` is ready,Some modification was applied in order to properly use the Dataset although some of these adjustments could be done in other places in code anyway we decided to do them in this part .\n",
        "The training consists 6182 images which has been used for Training and Validation , The Testing consists 20 images which has been used just for final evaluation of each model. \n",
        "\n",
        "Modifications : \n",
        "1.   There was a bug with names of Labels as some of them were saved with capital alphabets so it has been fixed. \n",
        "2.   Bounding Boxes modification,so each value has divided by 128.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbMCi35UFdKn"
      },
      "source": [
        "## Read the Trainnig Dataset CSV file \n",
        "path_to_train_csv_file = '/content/gdrive/My Drive/Kaggle/resized_images/ships_kiri.csv'\n",
        "\n",
        "train_files = pd.read_csv(path_to_train_csv_file,dtype='str')\n",
        "train_files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f66TNy9jG8GV"
      },
      "source": [
        "## Read the Testing Dataset CSV file \n",
        "path_to_test_csv_file = '/content/gdrive/My Drive/Kaggle/resized_images/test/ship_test.csv'\n",
        "\n",
        "test_files = pd.read_csv(path_to_test_csv_file,dtype='str')\n",
        "test_files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sRjrrdTHFVC"
      },
      "source": [
        "## (1) first modification\n",
        "# train bbox Normalization \n",
        "train_files['xmin'] = train_files['xmin'].apply(lambda x : int(x)/128)\n",
        "train_files['ymin'] = train_files['ymin'].apply(lambda x : int(x)/128)\n",
        "train_files['xmax'] = train_files['xmax'].apply(lambda x : int(x)/128)\n",
        "train_files['ymax'] = train_files['ymax'].apply(lambda x : int(x)/128)\n",
        "\n",
        "## test bbox Normalization \n",
        "\n",
        "test_files['xmin'] = test_files['xmin'].apply(lambda x : int(x)/128)\n",
        "test_files['ymin'] = test_files['ymin'].apply(lambda x : int(x)/128)\n",
        "test_files['xmax'] = test_files['xmax'].apply(lambda x : int(x)/128)\n",
        "test_files['ymax'] = test_files['ymax'].apply(lambda x : int(x)/128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb-2XDKMHLJ7"
      },
      "source": [
        "# count each the number images related to each category \n",
        "\n",
        "train_files['class'][train_files['class'] == 'Carrier'] = 'carrier'\n",
        "train_files['class'][train_files['class'] == 'Military'] = 'military'\n",
        "train_files['class'][train_files['class'] == 'Tanker'] = 'tanker'\n",
        "train_files['class'][train_files['class'] == 'Cruise'] = 'cruise'\n",
        "\n",
        "test_files['class'][test_files['class'] == 'criuse'] = 'cruise'\n",
        "\n",
        "train_files.set_index(['class' , 'filename']).count(level=\"class\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_q8ynUPHPta"
      },
      "source": [
        "## Data visualisation as the pie chart \n",
        "import plotly.express as px\n",
        "fig = px.pie(train_files, names='class', color_discrete_sequence=px.colors.sequential.RdBu)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5GCEa8GHX7B"
      },
      "source": [
        "## Data visualisation as the bar chart for Training Data\n",
        "dic = dict(train_files['class'].value_counts())\n",
        "fig = go.Figure(\n",
        "    data=[go.Bar(x=list(dic.keys()),y =list(train_files['class'].value_counts()))],\n",
        "    layout=go.Layout(\n",
        "        title=go.layout.Title(text=\"Quantity of each class\")\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZttbprpsHctl"
      },
      "source": [
        "## Data visualisation as the bar chart for Testing Data\n",
        "dic = dict(test_files['class'].value_counts())\n",
        "fig = go.Figure(\n",
        "    data=[go.Bar(x=list(dic.keys()),y =list(test_files['class'].value_counts()))],\n",
        "    layout=go.Layout(\n",
        "        title=go.layout.Title(text=\"Quantity of each class\")\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucxwUHlQH17X"
      },
      "source": [
        "## **Image Preprocessing** \n",
        "In this section : \n",
        "\n",
        "\n",
        "1.   images have imported for both Training and Testing.\n",
        "2.   Labels extracted from the Dataframe.\n",
        "3.   Bounding Boxes has extracted from Dataframe.\n",
        "\n",
        "\n",
        "The images with the help of corresponding `filename` has been read then append the array of image to a list.\n",
        "\n",
        "In the function `ImageLoader` below\n",
        "\n",
        "1.   The directory of folder is the input parameter containing the images for   different classes\n",
        "2.   Read the image file from the folder and convert it to the right format.\n",
        "3. Resize the image based on the input dimension required for the model here is 224.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehQu79JWHjj_"
      },
      "source": [
        "def imageLoader(path,img_list) : \n",
        "\n",
        "  data_img = []\n",
        "  # img_list = list(train_files['filename'])\n",
        "  for each in img_list:\n",
        "    # Each image path\n",
        "    each_path = os.path.join(path, each)\n",
        "    # Read each imagee\n",
        "    each_img = (cv2.imread(each_path))\n",
        "    # OpenCv default color is BGR. Convert it to RGB\n",
        "    each_img = cv2.cvtColor(each_img, cv2.COLOR_BGR2RGB)\n",
        "    # Resize the images\n",
        "    each_img_resized = cv2.resize(each_img, (224,224))\n",
        "\n",
        "    # image = each_img_resized.astype('float32')\n",
        "    # each_img_resized /= 255\n",
        "    # Save arrays to a list\n",
        "    data_img.append(each_img_resized)\n",
        "\n",
        "  return data_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLBaVTFWJ4BF"
      },
      "source": [
        "**training section**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NGcFKdlJtrA"
      },
      "source": [
        "# ground truth of bounding boxes\n",
        "column = ['xmin' , 'ymin' , 'xmax' ,'ymax']\n",
        "gt_bbox = train_files[column].to_numpy()\n",
        "# Labels \n",
        "gt_labels = train_files['class']\n",
        "\n",
        "## the data for further processing is saved in all_images variable \n",
        "path = '/content/gdrive/My Drive/Kaggle/all'\n",
        "train_list = list(train_files['filename'])\n",
        "\n",
        "all_images = imageLoader(path,train_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ-P-BdbKD8A"
      },
      "source": [
        "**Testing Section**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1Bbt68vKG09"
      },
      "source": [
        "# List of image names\n",
        "column = ['xmin' , 'ymin' , 'xmax' ,'ymax']\n",
        "test_list = list(test_files['filename'])\n",
        "path_test = '/content/gdrive/My Drive/Kaggle/resized_images/test/image/'\n",
        "\n",
        "test_data = imageLoader(path_test,test_list)\n",
        "# Converting list to numpy array\n",
        "TEST_images = np.array(test_data)\n",
        "print('Shape of test data: ', TEST_images.shape)\n",
        "\n",
        "\n",
        "TEST_bbox = test_files[column].to_numpy()\n",
        "TEST_labels = test_files['class']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfcMEeLSKghX"
      },
      "source": [
        "## **Convert the list of array of images to Numpy array**\n",
        "Also a Dictionary base on labels has created and assign a number to each category instead of categorical labels. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0GFUSdqKRJh"
      },
      "source": [
        "## Load each images with corresponding labels and bounding boxes\n",
        "def DataLoader(images , labels , bboxes) : \n",
        "\n",
        "  images_np = np.array(images)\n",
        "  labels_np = np.array(target_val)\n",
        "  bboxes_np = np.array(bboxes)\n",
        "\n",
        "  print('type of images : ' , type(images_np),' size of images : ',images_np.shape)\n",
        "  print('type of labels : ',type(labels_np),  ' size of labels : ',labels_np.shape)\n",
        "  print('type of Bboxes : ',type(bboxes_np),  ' size of bboxes : ',bboxes_np.shape)\n",
        "\n",
        "  return images_np , labels_np , bboxes_np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-tfMg7xLCT2"
      },
      "source": [
        "## create a dictionary in order to assign each of 5 labels to a number \n",
        "target_dict={k: v for v, k in enumerate(np.unique(gt_labels))}\n",
        "print(target_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1csvdVLNLEe4"
      },
      "source": [
        "target_val=  [target_dict[gt_labels[i]] for i in range(len(gt_labels))]\n",
        "TEST_labels_n = [target_dict[TEST_labels[i]] for i in range(len(TEST_labels))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvChRjfrLEiH"
      },
      "source": [
        "train_data = DataLoader(all_images,gt_labels,gt_bbox)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K-xBMhjLEle"
      },
      "source": [
        "images_all_np ,labels_all_np,bboxes_all_np = train_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXxPDKTFLN4b"
      },
      "source": [
        "## **Visual the images with corresponding bounding box**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-KiIWTYLOeU"
      },
      "source": [
        "## another dictionary for visualization of data (for np.argmax)\n",
        "target_dict2 = {0 : 'cargo', 1 : 'carrier', 2 : 'cruise', 3 : 'military', 4 : 'tanker'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asDsEopNMHmB"
      },
      "source": [
        "from PIL import Image\n",
        "import cv2\n",
        "from PIL import Image, ImageDraw\n",
        "def visualization (img_array , label , bbox , num) : \n",
        "  counter=0\n",
        "  plt.figure(figsize=(18, 28))\n",
        "  x  = len(img_array)\n",
        "  for i in np.random.randint(0,x,num*3) : \n",
        "    counter += 1\n",
        "    height , width,channel = np.shape(img_array[i])\n",
        "    ax = plt.subplot(3,num,counter)\n",
        "    xmin , ymin , xmax , ymax = bbox[i]\n",
        "    image = Image.fromarray((img_array[i]).astype(np.uint8))\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    draw.rectangle((int(xmin*width),int(ymin*height),int(xmax*width),int(ymax*height)),outline='green',width=2)\n",
        "    plt.imshow(image)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(target_dict2[label[i]])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR1esTQRMHq_"
      },
      "source": [
        "##just for check the one single output of function \n",
        "print('shape of image :', np.shape(images_all_np[0]),'\\n','type of image:', type(images_all_np[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaWjmyjSMHu1"
      },
      "source": [
        "images_all_np , labels_all_np,bboxes_all_np = train_data\n",
        "## num is number of columns of image in subplot function , \n",
        "## number of rows is constant by 3 \n",
        "num = 2\n",
        "\n",
        "visualization(images_all_np,labels_all_np,bboxes_all_np,num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9c0ygbDMcyy"
      },
      "source": [
        "# **Prepare Data for Models**\n",
        "1.   **Split the Data for training and validation**\n",
        "\n",
        "2.   **One Hot encoding**\n",
        "\n",
        "\n",
        "80% of images used for training and 20% for Validation in shuffle mode. \n",
        "\n",
        "**One Hot Encoding**\n",
        "\n",
        "In these cases, we would like to give the network more expressive power to learn a probability-like number for each possible label value. This can help in both making the problem easier for the network to model. When a one hot encoding is used for the output variable, it may offer a more nuanced set of predictions than a single label.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjN1Z1r8MHyR"
      },
      "source": [
        "image_train, image_test, label_train, label_test ,bbox_train , bbox_test = train_test_split(images_all_np,\n",
        "                                                                                            labels_all_np,\n",
        "                                                                                            bboxes_all_np,\n",
        "                                                                                            test_size =0.2,\n",
        "                                                                                            random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Shu6ZLMRNMvj"
      },
      "source": [
        "# one hot encoding \n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "train_labels_one_hot = to_categorical(label_train)\n",
        "test_labels_one_hot = to_categorical(label_test)\n",
        "## check\n",
        "print(train_labels_one_hot[2])\n",
        "print(test_labels_one_hot[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haHAVsZ8Qtzz"
      },
      "source": [
        "#**Models** \n",
        "two models have been used :\n",
        "\n",
        "1.   Multiple output model which has base of `MobileNetV2` \n",
        "2.   Splitted Model which has 2 models , first Xception for Classification and MobileNetV2 for regression\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cu8rhOvyRfQj"
      },
      "source": [
        "## **Multiple output**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJvtBD-YRuau"
      },
      "source": [
        "### Data Generator\n",
        "yield images , labels , bboxes "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_IptDzGQ1dZ"
      },
      "source": [
        "## Data generator \n",
        "def get_generator_train(features, labels,bbox, batch_size=16):\n",
        "  while True :\n",
        "    for n in range(int(len(features)/batch_size)):\n",
        "        yield features[n*batch_size:(n+1)*batch_size], [labels[n*batch_size:(n+1)*batch_size],bbox[n*batch_size:(n+1)*batch_size]]\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "def get_generator_test(features, labels,bbox, batch_size=16):\n",
        "  while True :\n",
        "    for n in range(int(len(features)/batch_size)):\n",
        "        yield features[n*batch_size:(n+1)*batch_size], [labels[n*batch_size:(n+1)*batch_size],bbox[n*batch_size:(n+1)*batch_size]]\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-okawdWQR6O4"
      },
      "source": [
        "training_generator = get_generator_train(image_train,train_labels_one_hot,bbox_train)\n",
        "testing_generator  = get_generator_test(image_test,test_labels_one_hot,bbox_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLOYy2B0R-gR"
      },
      "source": [
        "**So from now on we have batches of images and labels in each batch there are 16 images with size of `(16, 224, 224, 3)` and list of labels which has 2 section of `bounding boxes` and `ship class` with size of (16, 4) and (16, 5) respectively** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dshzmBkKR98h"
      },
      "source": [
        "image, label = next(training_generator)\n",
        "print(np.shape(image))\n",
        "print(label[0].shape)\n",
        "print(label[1].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48xZwSEcSItP"
      },
      "source": [
        "## An example from training set\n",
        "example , label = next(training_generator)\n",
        "image = example[0]\n",
        "class_id = np.argmax(label[0][0])\n",
        "coords = label[1][0]\n",
        "coords\n",
        "image = plot_bounding_box(image,coords,norm=True)\n",
        "plt.imshow(image)\n",
        "plt.title(target_dict2[class_id])\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnpMgCwCSI2I"
      },
      "source": [
        "# An example from validation set\n",
        "example , label = next(testing_generator)\n",
        "image = example[0]\n",
        "class_id = np.argmax(label[0][0])\n",
        "coords = label[1][0]\n",
        "coords\n",
        "image = plot_bounding_box(image,coords,norm=True)\n",
        "plt.imshow(image)\n",
        "plt.title(target_dict2[class_id])\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7U9DzwbSSlm"
      },
      "source": [
        "### Model configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-x3kzMySM19"
      },
      "source": [
        "import math\n",
        "EPOCHS = 15\n",
        "\n",
        "# image_train, image_test, label_train, label_test ,bbox_train , bbox_test\n",
        "# Choose a batch size\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# Get the length of the training set\n",
        "length_of_training_dataset = len(image_train)\n",
        "\n",
        "# Get the length of the validation set\n",
        "length_of_validation_dataset = len(image_test)\n",
        "\n",
        "print(length_of_training_dataset , length_of_validation_dataset)\n",
        "# Get the steps per epoch (may be a few lines of code)\n",
        "steps_per_epoch = math.ceil(length_of_training_dataset/BATCH_SIZE)\n",
        "\n",
        "print(steps_per_epoch)\n",
        "# get the validation steps (per epoch) (may be a few lines of code)\n",
        "validation_steps = length_of_validation_dataset//BATCH_SIZE\n",
        "if length_of_validation_dataset % BATCH_SIZE > 0:\n",
        "    validation_steps += 1\n",
        "    \n",
        "print(validation_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_5WaBAySXU4"
      },
      "source": [
        "# callbacks\n",
        "checkpoint_path_mlp = '/content/gdrive/My Drive/Kaggle/resized_images/Multi_weights'\n",
        "checkpoint_mlp = ModelCheckpoint(filepath=checkpoint_path_mlp,\n",
        "monitor='val_loss', save_best_only =True, save_weights_only=True, save_freq='epoch',\n",
        "                             mode='auto',\n",
        "                            verbose=1)\n",
        "earlystop = EarlyStopping(monitor='val_loss',patience=3,verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss',factor=0.1,patience=1,verbose=1,min_delta=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3_-aCbWSXZl"
      },
      "source": [
        "opt1 = tf.keras.optimizers.RMSprop(lr = 0.001)\n",
        "opt2 = tf.keras.optimizers.SGD(learning_rate=0.01,momentum=0.9)\n",
        "opt3 = tf.keras.optimizers.Adam(learning_rate=0.0002)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZbdFV7BSXeS"
      },
      "source": [
        "mobilenet_model = tf.keras.applications.MobileNetV2(input_shape=(224,224,3),include_top=False,weights='imagenet')\n",
        "# pass the inputs into this modle object to get a feature extractor for these inputs\n",
        "inputs = tf.keras.Input(shape=(224,224,3),name='image')\n",
        "feature_extractor = mobilenet_model(inputs)\n",
        "x2 = tf.keras.layers.GlobalAveragePooling2D()(feature_extractor)  \n",
        "    \n",
        "    # flatten layer\n",
        "x = tf.keras.layers.Flatten()(x2)\n",
        "    \n",
        "    # 1024 Dense layer, with relu\n",
        "x = tf.keras.layers.Dense(1024,activation='relu')(x)\n",
        "    \n",
        "    # 512 Dense layer, with relu\n",
        "x1 = tf.keras.layers.Dense(512,activation='relu')(x)\n",
        "\n",
        "    ## khodam ezafe kardam,###############################\n",
        "y_l = tf.keras.layers.Dropout(0.3)(x)\n",
        "y_l = tf.keras.layers.Dense(256,activation='relu')(x1)\n",
        "\n",
        "y_b = tf.keras.layers.Dense(512,activation='relu')(x1)\n",
        "y_b = tf.keras.layers.Dense(512,activation='relu')(y_b)\n",
        "y_b = tf.keras.layers.Dropout(0.3)(y_b)\n",
        "y_b = tf.keras.layers.Dense(256,activation='relu')(y_b)\n",
        "y_b = tf.keras.layers.Dropout(0.3)(y_b) \n",
        "y_b = tf.keras.layers.Dense(256,activation='relu')(y_b)   \n",
        "\n",
        "bounding_box_regression_output =tf.keras.layers.Dense(4,activation='relu',name='box_out')(y_l) \n",
        "label_output = tf.keras.layers.Dense(5,activation='softmax',name='class_out')(x2)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=[label_output,bounding_box_regression_output])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfqA1pOsSkVM"
      },
      "source": [
        "### Model's Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qR4qZSsqSf5C"
      },
      "source": [
        "tf.keras.utils.plot_model(model,'mult_input_output_model.png',show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sY4SEKMsSreV"
      },
      "source": [
        "### Model Compling and Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n81vzNaaSnap"
      },
      "source": [
        "model.compile(\n",
        "        optimizer=opt3,\n",
        "        loss = {'class_out' : 'categorical_crossentropy' ,'box_out' : 'mse'} ,\n",
        "        metrics = {'class_out' : 'accuracy' ,'box_out' : 'mae'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c9BjgfuSnnx"
      },
      "source": [
        "history =  model.fit(training_generator,\n",
        "                    steps_per_epoch=steps_per_epoch, \n",
        "                    validation_data = testing_generator,\n",
        "                    validation_steps=validation_steps,\n",
        "                    epochs=30,\n",
        "                     callbacks = [checkpoint_mlp,earlystop,reduce_lr])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5gQmaTHS3Ed"
      },
      "source": [
        "### result of training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ftp6gZHdSns9"
      },
      "source": [
        "result_visual(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-2yz5l0TfRy"
      },
      "source": [
        "### Evaluation Model on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPLgHLXVSnys"
      },
      "source": [
        "result_images(images = TEST_images,\n",
        "              gt_bbox=TEST_bbox,\n",
        "              gt_label = TEST_labels_n,\n",
        "              model_test=model,\n",
        "              model_classification = None,\n",
        "              model_reg= None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPsZSvx4Ts0V"
      },
      "source": [
        "## **Splitted Model**\n",
        "This one as already said includes 2 models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSU7_s1HT-N0"
      },
      "source": [
        "### **Classification Model** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW1Oj0kpT17B"
      },
      "source": [
        "#### Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7B59n-i7TwEk"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_gen = ImageDataGenerator(horizontal_flip=True,\n",
        "                               rotation_range = 45,\n",
        "                               zoom_range=0.2,\n",
        "                               height_shift_range = 0.5,\n",
        "                               width_shift_range = 0.5)\n",
        "\n",
        "validation_gen = ImageDataGenerator(horizontal_flip=True,\n",
        "                               rotation_range = 45,\n",
        "                               zoom_range=0.2,\n",
        "                               height_shift_range = 0.5,\n",
        "                               width_shift_range = 0.5)\n",
        "\n",
        "train_gen.fit(image_train)\n",
        "validation_gen.fit(image_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3SaWqQ_UBiN"
      },
      "source": [
        "train_gen= train_gen.flow(image_train, train_labels_one_hot, batch_size=32)\n",
        "val_gen  = validation_gen.flow(image_test, test_labels_one_hot, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stI6j1lxUDuM"
      },
      "source": [
        "## train \n",
        "images_gen , labels_gen = train_gen[7]\n",
        "plt.figure(figsize=(20, 20))\n",
        "for i in range(7) : \n",
        "  ax = plt.subplot(1,7,i+1)\n",
        "  plt.imshow((images_gen[i]).astype('uint8'))\n",
        "  plt.title(target_dict2[(np.argmax(labels_gen[i], axis=0))])\n",
        "  plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRFOF5bnUG-d"
      },
      "source": [
        "## test\n",
        "images_val , labels_val = val_gen[1]\n",
        "plt.figure(figsize=(20, 20))\n",
        "for i in range(7) : \n",
        "  ax = plt.subplot(1,7,i+1)\n",
        "  plt.imshow(images_val[i].astype('uint8'))\n",
        "  plt.title(target_dict2[(np.argmax(labels_val[i], axis=0))])\n",
        "  plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EkNm_f8U1kM"
      },
      "source": [
        "#### Model configuration "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQBqD-XoT-eu"
      },
      "source": [
        "from tensorflow.keras.applications.xception import Xception\n",
        "def get_Class_Model() : \n",
        "\n",
        "  # Defining the pretrained base model\n",
        "  base = Xception(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
        "  x = base.output\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  # Defining the head of the model where the prediction is conducted\n",
        "  head = Dense(5, activation='softmax')(x)\n",
        "  # Combining base and head \n",
        "  model = Model(inputs=base.input, outputs=head)\n",
        "  # Compiling the model\n",
        "  model.compile(optimizer=Adam(lr=0.0001), \n",
        "                loss = 'categorical_crossentropy', \n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25MChmf8Uiis"
      },
      "source": [
        "## callbacks\n",
        "checkpoint_path = '/content/gdrive/My Drive/Kaggle/resized_images/classification_weights2'\n",
        "checkpoint = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                             monitor='val_loss', \n",
        "                             save_best_only =True, \n",
        "                             save_weights_only=True, \n",
        "                             save_freq='epoch',\n",
        "                             mode='auto',\n",
        "                             verbose=1)\n",
        "earlystop = EarlyStopping(monitor='val_loss',min_delta=0.03,patience=3,verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss',factor=0.1,min_delta=0.02,patience=2,verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmQcz4ndU6QW"
      },
      "source": [
        "#### Classification Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFDPX1-7Ukha"
      },
      "source": [
        "classification_model = get_Class_Model()\n",
        "\n",
        "batch_size =32\n",
        "epochs = 15\n",
        "model = get_Class_Model()\n",
        "# Fitting the model with train and validation augmented datasets.\n",
        "history = model.fit_generator(train_gen,\n",
        "                              epochs = epochs,\n",
        "                              validation_data = val_gen,\n",
        "                              steps_per_epoch = image_train.shape[0] // batch_size,\n",
        "                              callbacks= [checkpoint,reduce_lr,earlystop])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5eOhYxSVATU"
      },
      "source": [
        "#### Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4HAIlwYUm1O"
      },
      "source": [
        "tf.keras.utils.plot_model(classification_model,'classification_model_output_model.png',show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZlGk0lJVE93"
      },
      "source": [
        "#### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_BPCzBLVEaj"
      },
      "source": [
        "## Confusion\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Predicting labels from X_test data\n",
        "y_pred = model.predict(image_test)\n",
        "\n",
        "# Converting prediction classes from one hot encoding to list\n",
        "# Argmax returns the position of the largest value\n",
        "y_pred_classes = np.argmax(y_pred, axis = 1)\n",
        "\n",
        "# Convert test labels from one hot encoding to list\n",
        "# y_test_classes = np.argmax(TEST_labels, axis = 1)\n",
        "\n",
        "# Create the confusion matrix\n",
        "confmx = confusion_matrix(label_test, y_pred_classes)\n",
        "f, ax = plt.subplots(figsize = (8,8))\n",
        "sns.heatmap(confmx, annot=True, fmt='.1f', ax = ax)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S29ubXF1VEqt"
      },
      "source": [
        "print(classification_report(label_test, y_pred_classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5_LCg5uVTlu"
      },
      "source": [
        "fig2 = go.Figure()\n",
        "fig2.add_trace(go.Scattergl(\n",
        "                     y=history.history['accuracy'],\n",
        "                     name='Train'))\n",
        "fig2.add_trace(go.Scattergl(\n",
        "                      y=history.history['val_accuracy'],\n",
        "                      name='Valid'))\n",
        "fig2.update_layout(height=500, \n",
        "                    width=700,\n",
        "                    title='ACCURACY',\n",
        "                    xaxis_title='Epoch',\n",
        "                    yaxis_title='Accuracy')\n",
        "fig2.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZHR_TouVViy"
      },
      "source": [
        "fig3 = go.Figure()\n",
        "fig3.add_trace(go.Scattergl(\n",
        "                      y=history.history['loss'],\n",
        "                      name='Train'))\n",
        "fig3.add_trace(go.Scattergl(\n",
        "                      y=history.history['val_loss'],\n",
        "                      name='Valid')\n",
        "                      )\n",
        "fig3.update_layout(height=500, width=700,\n",
        "                    title_text=\"Loss\",\n",
        "                    xaxis_title='Epoch',\n",
        "                    yaxis_title='Loss')\n",
        "\n",
        "\n",
        "\n",
        "fig3.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTNZcLdOVdAY"
      },
      "source": [
        "#### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzPOvnMoVbD-"
      },
      "source": [
        "# Predicting random 5 images\n",
        "sample_pred = model_test.predict(TEST_images)\n",
        "sample_classes = TEST_labels_n\n",
        "# Visualizing the predictions\n",
        "i = 0\n",
        "plt.figure(figsize=(12,9))\n",
        "for each in range(10):\n",
        "    i += 1\n",
        "    plt.subplot(2,5,i)\n",
        "    plt.imshow(TEST_images[each])\n",
        "    plt.title(target_dict2[((TEST_labels_n[each]))],color = 'green',size=15)\n",
        "    plt.xlabel('PREDICTION: ' + str(target_dict2[sample_classes[each]]),size=10,color='red')\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqjWw_qFVfU-"
      },
      "source": [
        "### **Regression Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iUzFETIVqlu"
      },
      "source": [
        "#### Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huvnQsh7V-vR"
      },
      "source": [
        "## Data generator \n",
        "def get_generator(features,bbox, batch_size=16):\n",
        "  while True :\n",
        "    for n in range(int(len(features)/batch_size)):\n",
        "        yield features[n*batch_size:(n+1)*batch_size], bbox[n*batch_size:(n+1)*batch_size]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovqen9ndWAua"
      },
      "source": [
        "training_generator = get_generator(image_train,bbox_train)\n",
        "testing_generator  = get_generator(image_test,bbox_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i6n_M_-WCjG"
      },
      "source": [
        "## An example from training set\n",
        "example , bbox = next(training_generator)\n",
        "image = example[0]*255\n",
        "# class_id = np.argmax(label[0])\n",
        "coords = bbox[0]\n",
        "coords\n",
        "image = plot_bounding_box(image,coords,norm=True)\n",
        "plt.imshow(image)\n",
        "# plt.title(target_dict2[class_id])\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T08QI6NVqs7"
      },
      "source": [
        "#### Model configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTgOQup7WFy2"
      },
      "source": [
        "import math\n",
        "EPOCHS = 15\n",
        "\n",
        "# image_train, image_test, label_train, label_test ,bbox_train , bbox_test\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# Get the length of the training set\n",
        "length_of_training_dataset = len(image_train)\n",
        "\n",
        "# Get the length of the validation set\n",
        "length_of_validation_dataset = len(image_test)\n",
        "\n",
        "print(length_of_training_dataset , length_of_validation_dataset)\n",
        "# Get the steps per epoch \n",
        "steps_per_epoch = math.ceil(length_of_training_dataset/BATCH_SIZE)\n",
        "\n",
        "print(steps_per_epoch)\n",
        "# get the validation steps (per epoch) \n",
        "validation_steps = length_of_validation_dataset//BATCH_SIZE\n",
        "if length_of_validation_dataset % BATCH_SIZE > 0:\n",
        "    validation_steps += 1\n",
        "    \n",
        "print(validation_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R9EVpoRWGZi"
      },
      "source": [
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "\n",
        "def get_Reg_model() : \n",
        "\n",
        "  inputs = tf.keras.Input(shape=(224,224,3),name='image')\n",
        "  mobilenet_model = tf.keras.applications.MobileNetV2(input_shape=(224,224,3),include_top=False,weights='imagenet')\n",
        "  feature_extractor = mobilenet_model(inputs)\n",
        "  x = tf.keras.layers.GlobalAveragePooling2D()(feature_extractor)\n",
        "  x = tf.keras.layers.Flatten()(x)\n",
        "  x = tf.keras.layers.Dense(1024,activation='relu')(x)\n",
        "  x = tf.keras.layers.Dense(512,activation='relu')(x)\n",
        "  \n",
        "\n",
        "  bounding_box_regression_output =tf.keras.layers.Dense(4,activation='relu')(x)\n",
        "  model = tf.keras.Model(inputs=inputs, outputs=bounding_box_regression_output)\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01,momentum=0.9), loss=\"mse\", metrics=[\"mae\",'accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0mPJjDfWLEO"
      },
      "source": [
        "# callbacks\n",
        "checkpoint_path_mlp = '/content/gdrive/My Drive/Kaggle/resized_images/Regression_weights2'\n",
        "checkpoint_mlp = ModelCheckpoint(filepath=checkpoint_path_mlp,monitor='val_loss', \n",
        "                                 save_best_only =True, \n",
        "                                 save_weights_only=True,\n",
        "                                 save_freq='epoch',\n",
        "                                 mode='auto',\n",
        "                                 verbose=1)\n",
        "earlystop = EarlyStopping(monitor='val_loss',patience=3,verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss',factor=0.1,patience=2,verbose=1,min_delta=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0pjLx83Vq0B"
      },
      "source": [
        "#### Regression training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iyG2yHJWWDm"
      },
      "source": [
        "history_REG =  REG_model.fit(training_generator,\n",
        "                    steps_per_epoch=steps_per_epoch, \n",
        "                    validation_data = testing_generator,\n",
        "                    validation_steps=validation_steps,\n",
        "                    epochs=30,\n",
        "                     callbacks = [checkpoint_mlp,reduce_lr,earlystop])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QRi4j13VrCQ"
      },
      "source": [
        "#### Model summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KRBL7m-WSit"
      },
      "source": [
        "# model.summary()\n",
        "tf.keras.utils.plot_model(REG_model,'mult_input_output_model.png',show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki1D8e8IVrJu"
      },
      "source": [
        "#### Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9lnLawTWbto"
      },
      "source": [
        "fig2 = go.Figure()\n",
        "\n",
        "\n",
        "fig2 = go.Figure()\n",
        "fig2.add_trace(go.Scattergl(\n",
        "                      y=history_REG.history['loss'],\n",
        "                      name='Train'))\n",
        "fig2.add_trace(go.Scattergl(\n",
        "                      y=history_REG.history['val_loss'],\n",
        "                      name='Valid'))\n",
        "fig2.update_layout(height=500, \n",
        "                    width=700,\n",
        "                    title='LOSS',\n",
        "                    xaxis_title='Epoch',\n",
        "                    yaxis_title='Loss')\n",
        "fig2.show()\n",
        "\n",
        "fig3 = go.Figure()\n",
        "fig3.add_trace(go.Scattergl(\n",
        "                      y=history_REG.history['mae'],\n",
        "                      name='Train'))\n",
        "fig3.add_trace(go.Scattergl(\n",
        "                      y=history_REG.history['val_mae'],\n",
        "                      name='Valid')\n",
        "                      )\n",
        "fig3.update_layout(height=500, width=700,\n",
        "                    title_text=\"Mean Absolute Error for age feature\",\n",
        "                    xaxis_title='Epoch',\n",
        "                    yaxis_title='Mean Absolute Error')\n",
        "\n",
        "\n",
        "\n",
        "fig3.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsNlKtUtV7f_"
      },
      "source": [
        "#### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUxwHaFbVhEk"
      },
      "source": [
        "prediction_bbox = REG_model.predict(TEST_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTUUNt0RWppz"
      },
      "source": [
        "plot_bounding_box(TEST_images[4],list(TEST_bbox[4]),list(prediction_bbox[4]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvgYegrrWrqf"
      },
      "source": [
        "## **Wrap all together** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i8z0PaKXHSk"
      },
      "source": [
        "## regressiom model\n",
        "path_reg = '/content/gdrive/My Drive/Kaggle/resized_images/Regression_weights2'\n",
        "model_reg2 = get_Reg_model()\n",
        "model_reg2.load_weights(path_reg)\n",
        "\n",
        "## classification model\n",
        "model_classification = get_Class_Model()\n",
        "model_classification.load_weights('/content/gdrive/My Drive/Kaggle/resized_images/classification_weights2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6v7bOC6XLSV"
      },
      "source": [
        "result_images(images=TEST_images,\n",
        "              gt_bbox = TEST_bbox,\n",
        "              gt_label = TEST_labels_n,\n",
        "              model_classification=model_classification,\n",
        "              model_test = None,\n",
        "              model_reg = model_reg2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}